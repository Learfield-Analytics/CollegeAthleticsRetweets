{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Code connects to proprietery database (Fanbase) and pulls in object 'workspace'\r\n",
        "# 'workspace' contains raw Twitter data from Supermetrics\r\n",
        "# Note that raw data from proprietary database is not shared with the public, \r\n",
        "# this script is intended to show the process for feature engineering only.\r\n",
        "\r\n",
        "tweet_dataset = Dataset.get_by_name(workspace, name='MIT Sloan - All Data - with ID - v2')\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Code connects to proprietery database (Fanbase) and pulls in object 'workspace'\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 'workspace' contains raw Twitter data from Supermetrics\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Note that raw data from proprietary database is not shared with the public, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# this script is intended to show the process for feature engineering only.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m tweet_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241m.\u001b[39mget_by_name(workspace, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMIT Sloan - All Data - with ID - v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1663775751009
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import pandas\r\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755391
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert raw twitter data to pandas dataframe\r\n",
        "twitter_raw = tweet_dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755412
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new dataframe with simplified columns\r\n",
        "#Note that 'PostMessage' contains the contents of a tweet, including text, links, and \r\n",
        "#emojis\r\n",
        "\r\n",
        "twitter2 = twitter_raw[['PostID','Date','Month_Year','VideoFlag','Handle',\r\n",
        "'ClientCode','Conference','Sport','PostMessage', \r\n",
        "'Impressions', 'VideoViews','Likes', 'Comments','Shares']]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755431
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace misspelled Main Athletics categories with correct spelling\r\n",
        "twitter2[\"Sport\"]=twitter2[\"Sport\"].str.replace('Main Atheltics', 'Main Athletics')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755452
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create field for month name and create indicator columns\r\n",
        "twitter2['Month_Name']=twitter2['Date'].dt.month_name()\r\n",
        "twitter2 = pd.get_dummies(twitter2, columns=['Month_Name'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755473
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create indicator columns for day of week of post\r\n",
        "twitter2['Day_of_Week']=twitter2['Date'].dt.day_name()\r\n",
        "twitter2 = pd.get_dummies(twitter2, columns=['Day_of_Week'])\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755492
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create indicator columns to determine sport \r\n",
        "twitter2 = pd.get_dummies(twitter2, columns=['Sport'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755515
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create indicator columns to determine conference of Twitter handle\r\n",
        "twitter2 = pd.get_dummies(twitter2, columns=['Conference'])\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755537
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Consolidate indicator columns\r\n",
        "\r\n",
        "#Flag whether a Tweet occurred Friday-Sunday\r\n",
        "twitter2.loc[(twitter2['Day_of_Week_Friday'] == 1)\r\n",
        "| (twitter2['Day_of_Week_Saturday'] == 1)\r\n",
        "| (twitter2['Day_of_Week_Sunday'] == 1), 'Fri_to_Sunday_Flag'] = 1\r\n",
        "\r\n",
        "twitter2.loc[(twitter2['Day_of_Week_Friday'] != 1)\r\n",
        "& (twitter2['Day_of_Week_Saturday'] != 1)\r\n",
        "& (twitter2['Day_of_Week_Sunday'] != 1), 'Fri_to_Sunday_Flag'] = 0\r\n",
        "\r\n",
        "\r\n",
        "#Flag whether the Tweet came from a 'Power 5' program\r\n",
        "twitter2.loc[(twitter2['Conference_ACC'] == 1)\r\n",
        "| (twitter2['Conference_B12'] == 1)\r\n",
        "| (twitter2['Conference_B10'] == 1)\r\n",
        "| (twitter2['Conference_SEC'] == 1)\r\n",
        "| (twitter2['Conference_Pac-12'] == 1)\r\n",
        ", 'P5_Conference_Flag'] = 1\r\n",
        "\r\n",
        "twitter2.loc[(twitter2['Conference_ACC'] != 1)\r\n",
        "& (twitter2['Conference_B12'] != 1)\r\n",
        "& (twitter2['Conference_B10'] != 1)\r\n",
        "& (twitter2['Conference_SEC'] != 1)\r\n",
        "& (twitter2['Conference_Pac-12'] != 1)\r\n",
        ", 'P5_Conference_Flag'] = 0\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Flag whether the sport was an Olympic Sport\r\n",
        "#Olympic Sport is deemed any sport that is not football or basketball\r\n",
        "twitter2.loc[(twitter2['Sport_Football'] != 1)\r\n",
        "& (twitter2['Sport_Women\\'s Basketball'] != 1)\r\n",
        "& (twitter2['Sport_Men\\'s Basketball'] != 1)\r\n",
        "& (twitter2['Sport_Main Athletics'] != 1)\r\n",
        ", 'Sport_Olympic'] = 1\r\n",
        "\r\n",
        "twitter2.loc[(twitter2['Sport_Football'] == 1)\r\n",
        "| (twitter2['Sport_Women\\'s Basketball'] == 1)\r\n",
        "| (twitter2['Sport_Men\\'s Basketball'] == 1)\r\n",
        "| (twitter2['Sport_Main Athletics'] == 1)\r\n",
        ", 'Sport_Olympic'] = 0\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Flag whether a Tweet occurred in Sept-Oct, Nov-Dec, etc. \r\n",
        "\r\n",
        "#Month - Sept-Oct\r\n",
        "twitter2.loc[(twitter2['Month_Name_September'] == 1)\r\n",
        "| (twitter2['Month_Name_October'] == 1)\r\n",
        ", 'Month_Sep_Oct'] = 1\r\n",
        "\r\n",
        "twitter2.loc[(twitter2['Month_Name_September'] != 1)\r\n",
        "& (twitter2['Month_Name_October'] != 1)\r\n",
        ", 'Month_Sep_Oct'] = 0\r\n",
        "\r\n",
        "#Month - Nov-Dec\r\n",
        "twitter2.loc[(twitter2['Month_Name_November'] == 1)\r\n",
        "| (twitter2['Month_Name_December'] == 1)\r\n",
        ", 'Month_Nov_Dec'] = 1\r\n",
        "\r\n",
        "twitter2.loc[(twitter2['Month_Name_November'] != 1)\r\n",
        "& (twitter2['Month_Name_December'] != 1)\r\n",
        ", 'Month_Nov_Dec'] = 0\r\n",
        "\r\n",
        "#Month - Jan-Feb\r\n",
        "twitter2.loc[(twitter2['Month_Name_January'] == 1)\r\n",
        "| (twitter2['Month_Name_February'] == 1)\r\n",
        ", 'Month_Jan_Feb'] = 1\r\n",
        "\r\n",
        "twitter2.loc[(twitter2['Month_Name_January'] != 1)\r\n",
        "& (twitter2['Month_Name_February'] != 1)\r\n",
        ", 'Month_Jan_Feb'] = 0\r\n",
        "\r\n",
        "#Month - Mar-Apr\r\n",
        "twitter2.loc[(twitter2['Month_Name_March'] == 1)\r\n",
        "| (twitter2['Month_Name_April'] == 1)\r\n",
        ", 'Month_Mar_Apr'] = 1\r\n",
        "\r\n",
        "twitter2.loc[(twitter2['Month_Name_March'] != 1)\r\n",
        "& (twitter2['Month_Name_April'] != 1)\r\n",
        ", 'Month_Mar_Apr'] = 0\r\n",
        "\r\n",
        "#Month - May-June\r\n",
        "twitter2.loc[(twitter2['Month_Name_May'] == 1)\r\n",
        "| (twitter2['Month_Name_June'] == 1)\r\n",
        ", 'Month_May_June'] = 1\r\n",
        "\r\n",
        "twitter2.loc[(twitter2['Month_Name_May'] != 1)\r\n",
        "& (twitter2['Month_Name_June'] != 1)\r\n",
        ", 'Month_May_June'] = 0\r\n",
        "\r\n",
        "#Month - July-Aug\r\n",
        "twitter2.loc[(twitter2['Month_Name_July'] == 1)\r\n",
        "| (twitter2['Month_Name_August'] == 1)\r\n",
        ", 'Month_July_Aug'] = 1\r\n",
        "\r\n",
        "twitter2.loc[(twitter2['Month_Name_July'] != 1)\r\n",
        "& (twitter2['Month_Name_August'] != 1)\r\n",
        ", 'Month_July_Aug'] = 0\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755557
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Share (Retweet) Rate Metric, as well as other engagement metrics\r\n",
        "#Share Rate defined as shares / impressions\r\n",
        "\r\n",
        "twitter2['Share_Rate'] = (twitter2['Shares']/twitter2['Impressions'])\r\n",
        "twitter2['Comment_Rate'] = (twitter2['Comments']/twitter2['Impressions'])\r\n",
        "twitter2['Like_Rate'] = (twitter2['Likes']/twitter2['Impressions'])\r\n",
        "twitter2['Total_SCLs'] = twitter2['Shares']+twitter2['Comments']+twitter2['Likes']\r\n",
        "twitter2['SCL_Rate']=twitter2['Total_SCLs']/twitter2['Impressions']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755600
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a PostMessage Column that has no hyperlinks. \r\n",
        "import re\r\n",
        "\r\n",
        "#Remove Hyperlinks\r\n",
        "twitter2['PostMessage'].astype(str)\r\n",
        "twitter2['PostMessage2'] = twitter2['PostMessage']\r\n",
        "twitter2['PostMessage2'] =twitter2['PostMessage2'].str.replace('http://\\S+|https://\\S+', '')\r\n",
        "twitter2['PostMessage2'] =twitter2['PostMessage2'].str.replace('http[s]?://\\S+', '')\r\n",
        "twitter2['PostMessage2'] =twitter2['PostMessage2'].str.replace(r\"http\\S+\", '')\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert PostMessage2 to lower, strip extra white space\r\n",
        "\r\n",
        "twitter2['PostMessage2']= twitter2['PostMessage2'].str.lower()\r\n",
        "twitter2['PostMessage2']= twitter2['PostMessage2'].str.strip()\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755643
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create postmessage fields with varying levels of info (emojis, spaces, etc)\r\n",
        "\r\n",
        "import unicodedata\r\n",
        "\r\n",
        "#Decode unicode text (required for string functions)\r\n",
        "twitter2[\"PostMessage3\"] = twitter2[\"PostMessage2\"].str.normalize('NFKD').str.lower().str.encode('ascii', 'ignore')\r\n",
        "twitter2[\"PostMessage4\"]=twitter2[\"PostMessage3\"].str.decode('utf8')\r\n",
        "twitter2[\"PostMessage5\"]=twitter2[\"PostMessage4\"].astype(str)\r\n",
        "\r\n",
        "#Remove spaces (still contains punctuation)\r\n",
        "twitter2[\"PostMessage6\"]=twitter2[\"PostMessage5\"].str.replace('\\n\\n', ' ')\r\n",
        "\r\n",
        "#Remove punctuation, symbols\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage6'].str.replace(',', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('.', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('!', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('?', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('@', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('#', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('$', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('%', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('&', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('+', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('-', '')\r\n",
        "twitter2['PostMessage7']= twitter2['PostMessage7'].str.replace('=', '')\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755662
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create PostMessage column dedicated to keeping hyperlinks to count links\r\n",
        "twitter2[\"PostMessage_H\"] = twitter2[\"PostMessage\"].str.normalize('NFKD').str.lower().str.encode('ascii', 'ignore')\r\n",
        "twitter2[\"PostMessage_H\"]=twitter2[\"PostMessage_H\"].str.decode('utf8')\r\n",
        "twitter2[\"PostMessage_H\"]=twitter2[\"PostMessage_H\"].astype(str)\r\n",
        "\r\n",
        "#Remove spaces -- still contains punctuation\r\n",
        "twitter2[\"PostMessage_H\"]=twitter2[\"PostMessage_H\"].str.replace('\\n\\n', ' ')\r\n",
        "\r\n",
        "#View all versions of 'PostMessage' code\r\n",
        "twitter2[[\"PostMessage\", \"PostMessage2\",\r\n",
        "                \"PostMessage3\", \"PostMessage4\",\r\n",
        "                \"PostMessage5\", \"PostMessage6\",\r\n",
        "                \"PostMessage7\",\r\n",
        "                \"PostMessage_H\"]].head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755687
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Count exclaimation marks, question marks,\r\n",
        "#hashtags, and mentions (Use postmessage field with punct)\r\n",
        "\r\n",
        "twitter2[\"Exclaim_Mark_Count\"]=twitter2[\"PostMessage6\"].map(lambda x: x.count(\"!\"))\r\n",
        "twitter2[\"Question_Mark_Count\"]=twitter2[\"PostMessage6\"].map(lambda x: x.count(\"?\"))\r\n",
        "twitter2[\"Hashtag_Count\"]=twitter2[\"PostMessage6\"].map(lambda x: x.count(\"#\"))\r\n",
        "twitter2[\"Mention_Count\"]=twitter2[\"PostMessage6\"].map(lambda x: x.count(\"@\"))\r\n",
        "\r\n",
        "\r\n",
        "#Count breaks in tweet (new line -- need to use PostMessage5)\r\n",
        "twitter2[\"Line_Break_Count\"]=twitter2[\"PostMessage5\"].map(lambda x: x.count(\"\\n\\n\"))\r\n",
        "\r\n",
        "#Post Length (number of characters)\r\n",
        "twitter2[\"PostLength_Count\"]=twitter2[\"PostMessage6\"].str.len()\r\n",
        "\r\n",
        "#Count hyperlink occurrences\r\n",
        "twitter2[\"Https_Count\"]=twitter2[\"PostMessage_H\"].map(lambda x: x.count('https'))\r\n",
        "twitter2[\"Link_Count\"]=twitter2[\"Https_Count\"]-1\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755717
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\r\n",
        "#if link is negative make it '0 links'\r\n",
        "twitter2['Link_Count_v2']=np.where(twitter2['Link_Count']<0,0,twitter2['Link_Count'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755745
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Count nubmer of emojis used\r\n",
        "import emojis\r\n",
        "\r\n",
        "twitter2[\"Emoji_Count\"]= twitter2['PostMessage'].apply(lambda x : emojis.count(str(x)))\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755770
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate column to decode emojis into text (':emoji:')\r\n",
        "#Decoded emojis can be used to classify whether certain types of emojis\r\n",
        "#Show up in Twitter content\r\n",
        "\r\n",
        "twitter2['Emoji_Text'] = twitter2['PostMessage'].apply(lambda x: emojis.decode(str(x)))\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755790
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create emoji Categories \r\n",
        "#https://www.webfx.com/tools/emoji-cheat-sheet/\r\n",
        "\r\n",
        "#Smiley\r\n",
        "emo_smiley_list = [':smile:', ':simple_smile:', ':blush:',':smiley:',':grinning:',':smiling_face:',\r\n",
        "':grinning_face:']               \r\n",
        "emo_smiley_list_pattern = '|'.join(emo_smiley_list)\r\n",
        "twitter2['Emo_Smiley_Flag'] = twitter2['Emoji_Text'].str.contains(emo_smiley_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Heart\r\n",
        "emo_heart_list = [':heart:',':red_heart:',':yellow_heart:', ':brown_heart:',':orange_heart:',\r\n",
        "':black_heart:',':white_heart:',\r\n",
        "':blue_heart:',':purple_heart:',':green_heart:',':heartbeat:',\r\n",
        "':heartpulse:',':two_hearts:',':revolving_hearts:',':cupid:',':sparkling_heart:']               \r\n",
        "emo_heart_list_pattern = '|'.join(emo_heart_list)\r\n",
        "twitter2['Emo_heart_Flag'] = twitter2['Emoji_Text'].str.contains(emo_heart_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Zap\r\n",
        "emo_zap_list = [':zap:']               \r\n",
        "emo_zap_list_pattern = '|'.join(emo_zap_list)\r\n",
        "twitter2['Emo_zap_Flag'] = twitter2['Emoji_Text'].str.contains(emo_zap_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Boom\r\n",
        "emo_boom_list = [':boom:',':collision:']               \r\n",
        "emo_boom_list_pattern = '|'.join(emo_boom_list)\r\n",
        "twitter2['Emo_boom_Flag'] = twitter2['Emoji_Text'].str.contains(emo_boom_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Laugh\r\n",
        "emo_laugh_list = [':laughing:',':joy:',':satisfied:']               \r\n",
        "emo_laugh_list_pattern = '|'.join(emo_laugh_list)\r\n",
        "twitter2['Emo_laugh_Flag'] = twitter2['Emoji_Text'].str.contains(emo_laugh_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Animals\r\n",
        "emo_animal_list = [':cat:',':dog:',':mouse:',':hamster:',':rabbit:',':wolf:',\r\n",
        "':frog:',':tiger:',':koala:',':bear:',':pig:',':pig_nose:',\r\n",
        "':cow:',':boar:',':monkey_face:',':monkey:',':horse:',\r\n",
        "':racehorse:',':camel:',':sheep:',':elephant:',':panda_face:',':snake:',\r\n",
        "':bird:',':baby_chick:',':hatched_chick:',':hatching_chick:',':chicken:',\r\n",
        "':penguin:',':turtle:',':bug:',':honeybee:',':ant:',':beetle:',\r\n",
        "':snail:',':octopus:',':tropical_fish:',':fish:',':whale:',':whale2:',\r\n",
        "':dolphin:',':cow2:',':ram:',':rat:',':water_buffalo:',':tiger2:',\r\n",
        "':rabbit2:',':dragon:',':goat:',':rooster:',':dog2:',':pig2:',':mouse2:',\r\n",
        "':ox:',':dragon_face:',':blowfish:',':crocodile:',':dromedary_camel:',\r\n",
        "':leopard:',':cat2:',':poodle:',':paw_prints:']\r\n",
        "emo_animal_list_pattern = '|'.join(emo_animal_list)\r\n",
        "twitter2['Emo_animal_Flag'] = twitter2['Emoji_Text'].str.contains(emo_animal_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Skull\r\n",
        "emo_skull_list = [':skull:',':skull_and_crossbones:']               \r\n",
        "emo_skull_list_pattern = '|'.join(emo_skull_list)\r\n",
        "twitter2['Emo_skull_Flag'] = twitter2['Emoji_Text'].str.contains(emo_skull_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Fire\r\n",
        "emo_fire_list = [':fire:']               \r\n",
        "emo_fire_list_pattern = '|'.join(emo_fire_list)\r\n",
        "twitter2['Emo_fire_Flag'] = twitter2['Emoji_Text'].str.contains(emo_fire_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Dash\r\n",
        "emo_dash_list = [':dash:']               \r\n",
        "emo_dash_list_pattern = '|'.join(emo_dash_list)\r\n",
        "twitter2['Emo_dash_Flag'] = twitter2['Emoji_Text'].str.contains(emo_dash_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Circle\r\n",
        "emo_circle_list = [':black_circle:',':white_circle:',':red_circle:',':large_blue_circle:',\r\n",
        "                  ':yellow_circle:',':green_circle:',':blue_circle:',':orange_circle:',\r\n",
        "                  ':purple_circle:', ':red_circle:',':brown_circle:']               \r\n",
        "emo_circle_list_pattern = '|'.join(emo_circle_list)\r\n",
        "twitter2['Emo_circle_Flag'] = twitter2['Emoji_Text'].str.contains(emo_circle_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Squares \r\n",
        "emo_Square_list = [':black_small_square:',':white_small_square:',':large_orange_diamond:',\r\n",
        "':black_large_square:',':black_medium_small_square:',':white_medium_small_square:',\r\n",
        "':white_medium_square:',':black_medium_square:',':white_large_square:',\r\n",
        "':white_square_button:',':black_square_button:',':negative_squared_cross_mark:',\r\n",
        "':green_square:',':red_square:',':blue_square:',':yellow_square:',':purple_square:',\r\n",
        "':black_square:',':white_square:',':orange_square:'\r\n",
        "]                \r\n",
        "emo_Square_list_pattern = '|'.join(emo_Square_list) \r\n",
        "twitter2['Emo_Square_Flag'] = twitter2['Emoji_Text'].str.contains(emo_Square_list_pattern).astype(int)\r\n",
        "\r\n",
        "#TV and Radio\r\n",
        "emo_TV_list = [':tv:',':radio:']                \r\n",
        "emo_TV_list_pattern = '|'.join(emo_TV_list) \r\n",
        "twitter2['Emo_TV_Radio_Flag'] = twitter2['Emoji_Text'].str.contains(emo_TV_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Chart\r\n",
        "emo_chart_list = [':bar_chart:',':chart_with_upwards_trend:']                \r\n",
        "emo_chart_list_pattern = '|'.join(emo_chart_list) \r\n",
        "twitter2['Emo_Bar_chart_Flag'] = twitter2['Emoji_Text'].str.contains(emo_chart_list_pattern).astype(int) \r\n",
        "\r\n",
        "#Arrows\r\n",
        "emo_arrows_list = [':arrow_down:',':arrow_up:',':arrow_heading_down:',\r\n",
        "':arrow_heading_up:',':arrows_counterclockwise:',':arrow_double_up',\r\n",
        "':arrow_double_down:',':arrow_backward:',':arrow_up_down:',':repeat']                 \r\n",
        "emo_arrows_list_pattern = '|'.join(emo_arrows_list)  \r\n",
        "twitter2['Emo_arrows_Flag'] = twitter2['Emoji_Text'].str.contains(emo_arrows_list_pattern).astype(int)  \r\n",
        "\r\n",
        "#VS\r\n",
        "emo_vs_list = [':vs:']                \r\n",
        "emo_vs_list_pattern = '|'.join(emo_vs_list) \r\n",
        "twitter2['Emo_vs_Flag'] = twitter2['Emoji_Text'].str.contains(emo_vs_list_pattern).astype(int) \r\n",
        "\r\n",
        "#Pushpin\r\n",
        "emo_Pushpin_list = [':round_pushpin:']                \r\n",
        "emo_Pushpin_list_pattern = '|'.join(emo_Pushpin_list) \r\n",
        "twitter2['Emo_Round_Pushpin_Flag'] = twitter2['Emoji_Text'].str.contains(emo_Pushpin_list_pattern).astype(int) \r\n",
        "\r\n",
        "#Sports objects\r\n",
        "emo_Ball_list = [':football:',':basketball:',':rugby_football:',':baseball:',\r\n",
        "':soccer:',':tennis:',':volleyball:',':softball:',':field_hockey:',':ice_hockey:',':lacrosse:',\r\n",
        "':golf:',':goal_net:']              \r\n",
        "emo_Ball_list_pattern = '|'.join(emo_Ball_list) \r\n",
        "twitter2['Emo_Sports_Objects_Flag'] = twitter2['Emoji_Text'].str.contains(emo_Ball_list_pattern).astype(int) \r\n",
        "\r\n",
        "#Eyes\r\n",
        "emo_eyes_list = [':eyes:']                \r\n",
        "emo_eyes_list_pattern = '|'.join(emo_eyes_list) \r\n",
        "twitter2['Emo_eyes_Flag'] = twitter2['Emoji_Text'].str.contains(emo_eyes_list_pattern).astype(int)\r\n",
        "\r\n",
        "#stuck out Eyes\r\n",
        "emo_stuck_out_eye_list = [':stuck_out_tongue_winking_eye:',':stuck_out_tongue_closed_eye:']                 \r\n",
        "emo_stuck_out_eye_list_pattern = '|'.join(emo_stuck_out_eye_list)  \r\n",
        "twitter2['Emo_stuck_out_eye_Flag'] = twitter2['Emoji_Text'].str.contains(emo_stuck_out_eye_list_pattern).astype(int)  \r\n",
        "\r\n",
        "#Rotating light\r\n",
        "emo_rot_light_list = [':rotating_light:']                \r\n",
        "emo_rot_light_list_pattern = '|'.join(emo_rot_light_list) \r\n",
        "twitter2['Emo_rotating_light_Flag'] = twitter2['Emoji_Text'].str.contains(emo_rot_light_list_pattern).astype(int) \r\n",
        "\r\n",
        "#Muscle\r\n",
        "emo_muscle_list = [':muscle:']                \r\n",
        "emo_muscle_list_pattern = '|'.join(emo_muscle_list)\r\n",
        "twitter2['Emo_muscle_Flag'] = twitter2['Emoji_Text'].str.contains(emo_muscle_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Alarm Clock\r\n",
        "emo_alarm_clock_list = [':alarm_clock:']                \r\n",
        "emo_alarm_clock_list_pattern = '|'.join(emo_alarm_clock_list) \r\n",
        "twitter2['Emo_alarm_clock_Flag'] = twitter2['Emoji_Text'].str.contains(emo_alarm_clock_list_pattern).astype(int) \r\n",
        "\r\n",
        "#Triumph\r\n",
        "emo_triumph_list = [':triumph:']                \r\n",
        "emo_triumph_list_pattern = '|'.join(emo_triumph_list) \r\n",
        "twitter2['Emo_triumph_Flag'] = twitter2['Emoji_Text'].str.contains(emo_triumph_list_pattern).astype(int) \r\n",
        "\r\n",
        "#Newspaper\r\n",
        "emo_newspaper_list = [':newspaper:',':newspaper_roll:']                \r\n",
        "emo_newspaper_list_pattern = '|'.join(emo_newspaper_list) \r\n",
        "twitter2['Emo_newspaper_Flag'] = twitter2['Emoji_Text'].str.contains(emo_newspaper_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Clap\r\n",
        "emo_clap_list = [':clap:']                \r\n",
        "emo_clap_list_pattern = '|'.join(emo_clap_list) \r\n",
        "twitter2['Emo_clap_Flag'] = twitter2['Emoji_Text'].str.contains(emo_clap_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Metal\r\n",
        "emo_metal_list = [':metal:']                \r\n",
        "emo_metal_list_pattern = '|'.join(emo_metal_list) \r\n",
        "twitter2['Emo_metal_Flag'] = twitter2['Emoji_Text'].str.contains(emo_metal_list_pattern).astype(int) \r\n",
        "\r\n",
        "#Computer\r\n",
        "emo_computer_list = [':computer:',':desktop_computer:']                \r\n",
        "emo_computer_list_pattern = '|'.join(emo_computer_list) \r\n",
        "twitter2['Emo_computer_Flag'] = twitter2['Emoji_Text'].str.contains(emo_computer_list_pattern).astype(int) \r\n",
        "\r\n",
        "#Link\r\n",
        "emo_link_list = [':link:']               \r\n",
        "emo_link_list_pattern = '|'.join(emo_link_list)\r\n",
        "twitter2['Emo_link_Flag'] = twitter2['Emoji_Text'].str.contains(emo_link_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Check Mark (different colors)\r\n",
        "emo_checkmark_list= [':heavy_check_mark:',':white_check_mark:', ':ballot_box_with_check:']\r\n",
        "emo_checkmark_list_pattern= '|'.join(emo_checkmark_list)\r\n",
        "twitter2['Emo_checkmark_Flag'] = twitter2['Emoji_Text'].str.contains(emo_checkmark_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Heavy_exclaimation_mark, bangbang\r\n",
        "emo_heavyexclaimation_list = [':heavy_exclamation_mark:', ':bangbang:', ':interrobang:']               \r\n",
        "emo_heavyexclaimation_list_pattern = '|'.join(emo_heavyexclaimation_list)\r\n",
        "twitter2['Emo_heavyexclaimation_Flag'] = twitter2['Emoji_Text'].str.contains(emo_heavyexclaimation_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Tickets\r\n",
        "emo_ticket_list = [':ticket:']               \r\n",
        "emo_ticket_list_pattern = '|'.join(emo_ticket_list)\r\n",
        "twitter2['Emo_ticket_Flag'] = twitter2['Emoji_Text'].str.contains(emo_ticket_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Camera flash\r\n",
        "emo_camera_list = [':camera_flash:', ':camera:' ]               \r\n",
        "emo_camera_list_pattern = '|'.join(emo_camera_list)\r\n",
        "twitter2['Emo_camera_Flag'] = twitter2['Emoji_Text'].str.contains(emo_camera_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Triangular flag on post\r\n",
        "emo_triflag_list = [':triangular_flag_on_post:']               \r\n",
        "emo_triflag_list_pattern = '|'.join(emo_triflag_list)\r\n",
        "twitter2['Emo_triflag_Flag'] = twitter2['Emoji_Text'].str.contains(emo_triflag_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Raised hands\r\n",
        "emo_raisedhands_list = [':raised_hands:']               \r\n",
        "emo_raisedhands_list_pattern = '|'.join(emo_raisedhands_list)\r\n",
        "twitter2['Emo_raisedhands_Flag'] = twitter2['Emoji_Text'].str.contains(emo_raisedhands_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Trophy, Ring, Medals\r\n",
        "emo_trophyring_list = [':trophy:', ':ring:', ':medal_sports:', ':1st_place_medal:', \r\n",
        "':2nd_place_medal:', ':3rd_place_medal:',':sports_medal:' ]               \r\n",
        "emo_trophyring_list_pattern = '|'.join(emo_trophyring_list)\r\n",
        "twitter2['Emo_trophyring_Flag'] = twitter2['Emoji_Text'].str.contains(emo_trophyring_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Call Me\r\n",
        "emo_callmehand_list = [':call_me_hand:']               \r\n",
        "emo_callmehand_list_pattern = '|'.join(emo_callmehand_list)\r\n",
        "twitter2['Emo_callmehand_Flag'] = twitter2['Emoji_Text'].str.contains(emo_callmehand_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Handshake\r\n",
        "emo_handshake_list = [':handshake:']               \r\n",
        "emo_handshake_list_pattern = '|'.join(emo_handshake_list)\r\n",
        "twitter2['Emo_handshake_Flag'] = twitter2['Emoji_Text'].str.contains(emo_handshake_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Punch\r\n",
        "emo_punch_list = [':punch:', ':facepunch:']               \r\n",
        "emo_punch_list_pattern = '|'.join(emo_punch_list)\r\n",
        "twitter2['Emo_punch_Flag'] = twitter2['Emoji_Text'].str.contains(emo_punch_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Star Struck\r\n",
        "emo_starstruck_list = [':star_struck:']               \r\n",
        "emo_starstruck_list_pattern = '|'.join(emo_starstruck_list)\r\n",
        "twitter2['Emo_starstruck_Flag'] = twitter2['Emoji_Text'].str.contains(emo_starstruck_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Sunglasses\r\n",
        "emo_sunglasses_list = [':sunglasses:']               \r\n",
        "emo_sunglasses_list_pattern = '|'.join(emo_sunglasses_list)\r\n",
        "twitter2['Emo_sunglasses_Flag'] = twitter2['Emoji_Text'].str.contains(emo_sunglasses_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Pointing\r\n",
        "emo_point_list = [':point_up:', ':point_down:', ':point_left:', ':point_right:', ':point_up_2:']               \r\n",
        "emo_point_list_pattern = '|'.join(emo_point_list)\r\n",
        "twitter2['Emo_point_Flag'] = twitter2['Emoji_Text'].str.contains(emo_point_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Movie\r\n",
        "emo_movie_list = [':movie_camera:', ':clapper:', ':cinema:']               \r\n",
        "emo_movie_list_pattern = '|'.join(emo_movie_list)\r\n",
        "twitter2['Emo_movie_Flag'] = twitter2['Emoji_Text'].str.contains(emo_movie_list_pattern).astype(int)\r\n",
        "\r\n",
        "#OK hand\r\n",
        "emo_okhand_list = [':ok_hand:']               \r\n",
        "emo_okhand_list_pattern = '|'.join(emo_okhand_list)\r\n",
        "twitter2['Emo_okhand_Flag'] = twitter2['Emoji_Text'].str.contains(emo_okhand_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Numbers\r\n",
        "emo_numbers_list = [':one:', ':two:', ':three:', ':four:', ':five:',\r\n",
        " ':six:', ':seven:', ':eight:', ':nine:', ':keycap_ten:', ':1234:', ':zero:']               \r\n",
        "emo_numbers_list_pattern = '|'.join(emo_numbers_list)\r\n",
        "twitter2['Emo_numbers_Flag'] = twitter2['Emoji_Text'].str.contains(emo_numbers_list_pattern).astype(int)\r\n",
        "\r\n",
        "#GOAT\r\n",
        "emo_goat_list = [':goat:']               \r\n",
        "emo_goat_list_pattern = '|'.join(emo_goat_list)\r\n",
        "twitter2['Emo_goat_Flag'] = twitter2['Emoji_Text'].str.contains(emo_goat_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Imp\r\n",
        "emo_imp_list = [':imp:', ':smiling_imp:' ]               \r\n",
        "emo_imp_list_pattern = '|'.join(emo_imp_list)\r\n",
        "twitter2['Emo_imp_Flag'] = twitter2['Emoji_Text'].str.contains(emo_imp_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Weather\r\n",
        "emo_weather_list = [':sunny:', ':umbrella:', ':cloud:', ':snowflake:', ':snowman:']               \r\n",
        "emo_weather_list_pattern = '|'.join(emo_weather_list)\r\n",
        "twitter2['Emo_weather_Flag'] = twitter2['Emoji_Text'].str.contains(emo_weather_list_pattern).astype(int)\r\n",
        "\r\n",
        "#USA Flag\r\n",
        "emo_usflag_list = [':us:']               \r\n",
        "emo_usflag_list_pattern = '|'.join(emo_usflag_list)\r\n",
        "twitter2['Emo_usflag_Flag'] = twitter2['Emoji_Text'].str.contains(emo_usflag_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Thumbs up\r\n",
        "emo_thumbsup_list = [':thumbsup:']               \r\n",
        "emo_thumbsup_list_pattern = '|'.join(emo_thumbsup_list)\r\n",
        "twitter2['Emo_thumbsup_Flag'] = twitter2['Emoji_Text'].str.contains(emo_thumbsup_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Thumbs down\r\n",
        "emo_thumbsdown_list = [':thumbsdown:']               \r\n",
        "emo_thumbsdown_list_pattern = '|'.join(emo_thumbsdown_list)\r\n",
        "twitter2['Emo_thumbsdown_Flag'] = twitter2['Emoji_Text'].str.contains(emo_thumbsdown_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Peace (V) Sign\r\n",
        "emo_peace_list = [':v:']               \r\n",
        "emo_peace_list_pattern = '|'.join(emo_peace_list)\r\n",
        "twitter2['Emo_peacehand_Flag'] = twitter2['Emoji_Text'].str.contains(emo_peace_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Graduation Cap\r\n",
        "emo_gradcap_list = [':mortar_board:']               \r\n",
        "emo_gradcap_list_pattern = '|'.join(emo_gradcap_list)\r\n",
        "twitter2['Emo_gradcap_Flag'] = twitter2['Emoji_Text'].str.contains(emo_gradcap_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Celebration\r\n",
        "emo_celebration_list = [':tada:', ':confetti_ball:' ]               \r\n",
        "emo_celebration_list_pattern = '|'.join(emo_celebration_list)\r\n",
        "twitter2['Emo_celebration_Flag'] = twitter2['Emoji_Text'].str.contains(emo_celebration_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Noise\r\n",
        "emo_noise_list = [':speaker:', ':loudspeaker:', ':mega:']               \r\n",
        "emo_noise_list_pattern = '|'.join(emo_noise_list)\r\n",
        "twitter2['Emo_noise_Flag'] = twitter2['Emoji_Text'].str.contains(emo_noise_list_pattern).astype(int)\r\n",
        "\r\n",
        "#xmas\r\n",
        "emo_xmas_list = [':santa:', ':christmas_tree:', ':gift:']               \r\n",
        "emo_xmas_list_pattern = '|'.join(emo_xmas_list)\r\n",
        "twitter2['Emo_xmas_Flag'] = twitter2['Emoji_Text'].str.contains(emo_xmas_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Halloween\r\n",
        "emo_halloween_list = [':jack_o_lantern:', ':ghost:']               \r\n",
        "emo_halloween_list_pattern = '|'.join(emo_halloween_list)\r\n",
        "twitter2['Emo_halloween_Flag'] = twitter2['Emoji_Text'].str.contains(emo_halloween_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Plants\r\n",
        "emo_plants_list = [':cherry_blossom:', ':tulip:', ':four_leaf_clover:',\r\n",
        " ':rose:', ':sunflower:', ':hibiscus:', ':maple_leaf:', ':leaves:', \r\n",
        " ':fallen_leaf:', ':herb:', ':mushroom:', ':cactus:', ':palm_tree:',\r\n",
        "  ':evergreen_tree:', ':deciduous_tree:', ':chestnut:', ':seedling:',\r\n",
        "   ':blossom:', ':ear_of_rice:']               \r\n",
        "emo_plants_list_pattern = '|'.join(emo_plants_list)\r\n",
        "twitter2['Emo_plants_Flag'] = twitter2['Emoji_Text'].str.contains(emo_plants_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Airplane\r\n",
        "emo_airplane_list = [':airplane:']               \r\n",
        "emo_airplane_list_pattern = '|'.join(emo_airplane_list)\r\n",
        "twitter2['Emo_airplane_Flag'] = twitter2['Emoji_Text'].str.contains(emo_airplane_list_pattern).astype(int)\r\n",
        "\r\n",
        "#House\r\n",
        "emo_house_list = [':house:', ':house_with_garden:']               \r\n",
        "emo_house_list_pattern = '|'.join(emo_house_list)\r\n",
        "twitter2['Emo_house_Flag'] = twitter2['Emoji_Text'].str.contains(emo_house_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Calendar\r\n",
        "emo_calendar_list = [':calendar:', ':date:']               \r\n",
        "emo_calendar_list_pattern = '|'.join(emo_calendar_list)\r\n",
        "twitter2['Emo_calendar_Flag'] = twitter2['Emoji_Text'].str.contains(emo_calendar_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Money\r\n",
        "emo_money_list = [':moneybag:', ':dollar:', ':money_with_wings:']               \r\n",
        "emo_money_list_pattern = '|'.join(emo_money_list)\r\n",
        "twitter2['Emo_money_Flag'] = twitter2['Emoji_Text'].str.contains(emo_money_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Hour glass\r\n",
        "emo_hourglass_list = [':hourglass:', ':hourglass_flowing_sand:']               \r\n",
        "emo_hourglass_list_pattern = '|'.join(emo_hourglass_list)\r\n",
        "twitter2['Emo_hourglass_Flag'] = twitter2['Emoji_Text'].str.contains(emo_hourglass_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Exploding Head\r\n",
        "emo_exploding_head_list = [':exploding_head:']\r\n",
        "emo_exploding_head_list_pattern = '|'.join(emo_exploding_head_list)\r\n",
        "twitter2['Emo_exploding_head_Flag'] = twitter2['Emoji_Text'].str.contains(emo_exploding_head_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Wave\r\n",
        "emo_wave_list = [':wave:']\r\n",
        "emo_wave_list_pattern = '|'.join(emo_wave_list)\r\n",
        "twitter2['Emo_wave_Flag'] = twitter2['Emoji_Text'].str.contains(emo_wave_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Speech and thought bubbles\r\n",
        "emo_speech_thought_bubble_list = [':speech_balloon:',':thought_balloon:']\r\n",
        "emo_speech_thought_bubble_list_pattern = '|'.join(emo_speech_thought_bubble_list)\r\n",
        "twitter2['Emo_speech_thought_bubble_Flag'] = twitter2['Emoji_Text'].str.contains(emo_speech_thought_bubble_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Stars\r\n",
        "emo_star_list = [':sparkles:', ':star:', ':star2:']\r\n",
        "emo_star_list_pattern = '|'.join(emo_star_list)\r\n",
        "twitter2['Emo_star_Flag'] = twitter2['Emoji_Text'].str.contains(emo_star_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Lock\r\n",
        "emo_lock_list = [':unlock:', ':lock:', ':closed_lock_with_key:']\r\n",
        "emo_lock_list_pattern = '|'.join(emo_lock_list)\r\n",
        "twitter2['Emo_lock_Flag'] = twitter2['Emoji_Text'].str.contains(emo_lock_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Books\r\n",
        "emo_book_list = [':books:', ':green_book:', ':blue_book:', ':orange_book:',\r\n",
        "':red_book:', ':open_book:',\r\n",
        "':notebook:', ':notebook_with_decorative_cover:', ':ledger:']\r\n",
        "emo_book_list_pattern = '|'.join(emo_book_list)\r\n",
        "twitter2['Emo_book_Flag'] = twitter2['Emoji_Text'].str.contains(emo_book_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Scream\r\n",
        "emo_scream_list = [':scream:']\r\n",
        "emo_scream_list_pattern = '|'.join(emo_scream_list)\r\n",
        "twitter2['Emo_scream_Flag'] = twitter2['Emoji_Text'].str.contains(emo_scream_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Intellectual Property\r\n",
        "emo_intellprop_list = [':copyright:', ':registered:', ':tm:']\r\n",
        "emo_intellprop_list_pattern = '|'.join(emo_intellprop_list)\r\n",
        "twitter2['Emo_intellprop_Flag'] = twitter2['Emoji_Text'].str.contains(emo_intellprop_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Hot/Sweaty Face\r\n",
        "emo_hot_face_list = [':hot_face:']\r\n",
        "emo_hot_face_list_pattern = '|'.join(emo_hot_face_list)\r\n",
        "twitter2['Emo_hot_face_Flag'] = twitter2['Emoji_Text'].str.contains(emo_hot_face_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Signle Eye\r\n",
        "emo_single_eye_list = [':eye:']\r\n",
        "emo_single_eye_list_pattern = '|'.join(emo_single_eye_list)\r\n",
        "twitter2['Emo_single_eye_Flag'] = twitter2['Emoji_Text'].str.contains(emo_single_eye_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Shout\r\n",
        "emo_shout_list = [':speaking_head:']\r\n",
        "emo_shout_list_pattern = '|'.join(emo_shout_list)\r\n",
        "twitter2['Emo_shout_Flag'] = twitter2['Emoji_Text'].str.contains(emo_shout_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Consolidate all hand gestures\r\n",
        "emo_handgesture_list = [':thumbsup:',':clap:',':metal:',':raised_hands:',':call_me_hand:',':handshake:',\r\n",
        "':punch:', ':facepunch:',':wave:',':point_up:', ':point_down:', ':point_left:', ':point_right:', ':point_up_2:',\r\n",
        "':ok_hand:']\r\n",
        "emo_handgesture_list_pattern = '|'.join(emo_handgesture_list)\r\n",
        "twitter2['Emo_handgesture_Flag'] = twitter2['Emoji_Text'].str.contains(emo_handgesture_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775755815
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import packages for sentiment analysis\r\n",
        "import nltk\r\n",
        "\r\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756470
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create sentiment scores using VADER lexicon (pos, neg, and neutral)\r\n",
        "\r\n",
        "#Create a column that contains all sentiment polarity scores (pos, neg, neu)\r\n",
        "\r\n",
        "twitter2['SentScore'] = twitter2['PostMessage6'].apply(lambda x: sid.polarity_scores(x))\r\n",
        "\r\n",
        "\r\n",
        "#Create additional columns with only pos, neg, and neutral sentiment score results\r\n",
        "\r\n",
        "twitter2['SentScore_NEG'] = (twitter2['SentScore'].astype(str)\r\n",
        "                                .str.split(\",\", n=1, expand=True)\r\n",
        "                                .loc[:,0]\r\n",
        "                                .str.replace(\"{'neg':\",\"\")\r\n",
        "                                .str.strip()\r\n",
        "                                .astype(float)\r\n",
        "                               )\r\n",
        "\r\n",
        "twitter2['SentScore_NEU'] = (twitter2['SentScore'].astype(str)\r\n",
        "                                .str.split(\",\", n=2, expand=True)\r\n",
        "                                .loc[:,1]\r\n",
        "                                .str.replace(\"'neu':\",\"\")\r\n",
        "                                .str.strip()\r\n",
        "                                .astype(float)\r\n",
        "                              )\r\n",
        "\r\n",
        "twitter2['SentScore_POS'] = (twitter2['SentScore'].astype(str)\r\n",
        "                                .str.rsplit(\",\", n=2, expand=True)\r\n",
        "                                .loc[:,1]\r\n",
        "                                .str.replace(\"'pos':\",\"\")\r\n",
        "                                .str.strip()\r\n",
        "                                .astype(float)\r\n",
        "                               )\r\n",
        "\r\n",
        "twitter2['SentScore_Compound'] = (twitter2['SentScore'].astype(str)\r\n",
        "                                .str.split(\",\", n=4, expand=True)\r\n",
        "                                .loc[:,3]\r\n",
        "                                .str.replace(\"'compound':\",\"\")\r\n",
        "                                .str.replace('}','')\r\n",
        "                                .str.strip()\r\n",
        "                                .astype(float)\r\n",
        "                               )\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756505
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import packages for parts of speech tagging\r\n",
        "\r\n",
        "from nltk import word_tokenize, pos_tag, pos_tag_sents\r\n",
        "  \r\n",
        "#Create a column that returns parts of speech & associated counts\r\n",
        "twitter2['POS']=pos_tag_sents(twitter2['PostMessage7'].apply(word_tokenize).tolist())\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756548
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create columns to count the # of words for specific parts of speech\r\n",
        "#Force 'POS' column to string\r\n",
        "twitter2[\"POS_Str\"]=twitter2[\"POS\"].astype(str)\r\n",
        "\r\n",
        "\r\n",
        "#Count the number of nouns, verbs, adjectives, etc \r\n",
        "#Create a new column for each part of speech counting the number of occurrences\r\n",
        "\r\n",
        "\r\n",
        "#POS Abbreviation Meanings\r\n",
        "\r\n",
        "#CC\tcoordinating conjunction\r\n",
        "#CD\tcardinal digit\r\n",
        "#DT\tdeterminer\r\n",
        "#EX\texistential there\r\n",
        "#FW\tforeign word\r\n",
        "#IN\tpreposition/subordinating conjunction\r\n",
        "#JJ\tThis NLTK POS Tag is an adjective (large)\r\n",
        "#JJR\tadjective, comparative (larger)\r\n",
        "#JJS\tadjective, superlative (largest)\r\n",
        "#LS\tlist market\r\n",
        "#MD\tmodal (could, will)\r\n",
        "#NN\tnoun, singular (cat, tree)\r\n",
        "#NNS\tnoun plural (desks)\r\n",
        "#NNP\tproper noun, singular (sarah)\r\n",
        "#NNPS\tproper noun, plural (indians or americans)\r\n",
        "#PDT\tpredeterminer (all, both, half)\r\n",
        "#POS\tpossessive ending (parent\\ ‘s)\r\n",
        "#PRP\tpersonal pronoun (hers, herself, him, himself)\r\n",
        "#PRP$\tpossessive pronoun (her, his, mine, my, our )\r\n",
        "#RB\tadverb (occasionally, swiftly)\r\n",
        "#RBR\tadverb, comparative (greater)\r\n",
        "#RBS\tadverb, superlative (biggest)\r\n",
        "#RP\tparticle (about)\r\n",
        "#TO\tinfinite marker (to)\r\n",
        "#UH\tinterjection (goodbye)\r\n",
        "#VB\tverb (ask)\r\n",
        "#VBG\tverb gerund (judging)\r\n",
        "#VBD\tverb past tense (pleaded)\r\n",
        "#VBN\tverb past participle (reunified)\r\n",
        "#VBP\tverb, present tense not 3rd person singular(wrap)\r\n",
        "#VBZ\tverb, present tense with 3rd person singular (bases)\r\n",
        "#WDT\twh-determiner (that, what)\r\n",
        "#WP\twh- pronoun (who)\r\n",
        "#WRB\twh- adverb (how)\r\n",
        "\r\n",
        "\r\n",
        "twitter2[\"POS_Noun_Sing_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'NN')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Noun_Plural_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'NNS')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Noun_Proper_Sing_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'NNP')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Noun_Proper_Plural_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'NNPS')\"))\r\n",
        "\r\n",
        "\r\n",
        "twitter2[\"POS_Verb_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'VB')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Verb_Gerund_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'VBG')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Verb_PastTense_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'VBD')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Verb_PastPartic_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'VBN')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Verb_PT_Not3rdPerSingular_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'VBP')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Verb_PT_With3rdPerSingular_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'VBZ')\"))\r\n",
        "\r\n",
        "\r\n",
        "twitter2[\"POS_Adjective_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'JJ')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Adjective_Comparative_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'JJR')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Adjective_Superlative_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'JJS')\"))\r\n",
        "\r\n",
        "\r\n",
        "twitter2[\"POS_Adverb_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'RB')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Adverb_Comparative_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'RBR')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Adverb_Superlative_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'RBS')\"))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "twitter2[\"POS_Modal_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'MD')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Cardinal_Digit_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'CD')\"))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "twitter2[\"POS_Personal_Pronoun_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'PRP')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Possessive_Pronoun_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'PRP$')\"))\r\n",
        "\r\n",
        "\r\n",
        "twitter2[\"POS_Coord_Conj_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'CC')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Determiner_Pronoun_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'DT')\"))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "twitter2[\"POS_Preposition_SubordConj_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'IN')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Predeterminer_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'PDT')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Particle_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'RP')\"))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "twitter2[\"POS_Interjection_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'UH')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_Possessive_End_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'POS')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_InfiniteMarker_End_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'TO')\"))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "twitter2[\"POS_WH_Determiner_End_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'WDT')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_WH_Pronoun_End_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'WP')\"))\r\n",
        "\r\n",
        "twitter2[\"POS_WH_Adverb_End_Count\"]=twitter2[\"POS_Str\"].map(lambda x: x.count(\"'WRB')\"))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756577
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Consolidate parts of speech \r\n",
        "\r\n",
        "#Verbs\r\n",
        "twitter2['Total_Verb_Count']= twitter2[\"POS_Verb_Count\"] + twitter2[\"POS_Verb_Gerund_Count\"]+ twitter2[\"POS_Verb_PastTense_Count\"]+ twitter2[\"POS_Verb_PastPartic_Count\"]+ twitter2[\"POS_Verb_PT_Not3rdPerSingular_Count\"]+ twitter2[\"POS_Verb_PT_With3rdPerSingular_Count\"]\r\n",
        "\r\n",
        "#Adjectives \r\n",
        "twitter2['Total_Adjective_Count']=twitter2[\"POS_Adjective_Count\"] + twitter2[\"POS_Adjective_Comparative_Count\"] + twitter2[\"POS_Adjective_Superlative_Count\"]\r\n",
        "\r\n",
        "#Adverbs\r\n",
        "twitter2['Total_Adverbs_Count']=twitter2[\"POS_Adverb_Count\"] + twitter2[\"POS_Adverb_Comparative_Count\"] + twitter2[\"POS_Adverb_Superlative_Count\"]\r\n",
        "\r\n",
        "#Noun Count\r\n",
        "twitter2['Total_Noun_Count']=twitter2[\"POS_Noun_Sing_Count\"] + twitter2[\"POS_Noun_Plural_Count\"] + twitter2[\"POS_Noun_Proper_Sing_Count\"] + twitter2[\"POS_Noun_Proper_Plural_Count\"]\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756620
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a column for word count\r\n",
        "\r\n",
        "twitter2['Word_Count']= twitter2['PostMessage6'].str.split().map(len)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756645
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create fields with % of words as nouns, verbs, adjectives, and adverbs\r\n",
        "\r\n",
        "twitter2['Total_Verb_Perc_of_Words'] = twitter2['Total_Verb_Count'] / twitter2['Word_Count']\r\n",
        "\r\n",
        "twitter2['Total_Adjective_Perc_of_Words'] = twitter2['Total_Adjective_Count'] / twitter2['Word_Count']\r\n",
        "\r\n",
        "twitter2['Total_Adverb_Perc_of_Words'] = twitter2['Total_Adverbs_Count'] / twitter2['Word_Count']\r\n",
        "\r\n",
        "twitter2['Total_Noun_Perc_of_Words'] = twitter2['Total_Noun_Count'] / twitter2['Word_Count']\r\n",
        "\r\n",
        "twitter2['Total_Digit_Perc_of_Words']=twitter2['POS_Cardinal_Digit_Count']/ twitter2['Word_Count']\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756663
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# At this point, proprietary data is pulled into the workspace\r\n",
        "# brand_dataset is a list of brand names and Twitter handles stored\r\n",
        "# in Fanbase, as well as university athletics & non-athletics handles/names, \r\n",
        "# and professional sports handles/names\r\n",
        "\r\n",
        "brand_dataset = Dataset.get_by_name(workspace, name='dimContent + dimBrand')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756684
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to pandas dataframe\r\n",
        "brands = brand_dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756703
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataframe with Non University brand twitter handles \r\n",
        "brands_NonUniv = brands[~brands.unified_industry_name.isin([\"University - Athletics\", \r\n",
        "\"University - Departments/Colleges\",\r\n",
        "\"University - Alumni Association\",\r\n",
        "\"Entertainment/Recreation - Major League Sports\"])]\r\n",
        "\r\n",
        "#dataframe with University Athletics handles \r\n",
        "brands_UnivAth = brands[brands.unified_industry_name.isin([\"University - Athletics\"])]\r\n",
        "\r\n",
        "#dataframe with Other University handles \r\n",
        "brands_UnivOther = brands[brands.unified_industry_name.isin([ \r\n",
        "\"University - Departments/Colleges\",\r\n",
        "\"University - Alumni Association\"])]\r\n",
        "\r\n",
        "#dataframe with PRO SPORTS handles \r\n",
        "brands_ProSports = brands[brands.unified_industry_name.isin([ \r\n",
        "\"Entertainment/Recreation - Major League Sports\"])]\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756725
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset brand dataframe to take a single columns (twitter handle)\r\n",
        "#Create pattern for brand twitter handles (i.e. @delta)\r\n",
        "\r\n",
        "brands_NonUniv['twitter_handle']=brands_NonUniv['twitter_handle'].astype(str)\r\n",
        "brands_NonUniv['twitter_handle']=brands_NonUniv['twitter_handle'].str.lower()\r\n",
        "brand_NonUniv_Handles_list = brands_NonUniv[\"twitter_handle\"].values.tolist()\r\n",
        "brand_NonUniv_Handles_list_pattern = '|'.join(brand_NonUniv_Handles_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756747
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset brand dataframe to take a single columns (twitter handle)\r\n",
        "#Create pattern for university athletics handles (ie.e. @ou_athletics)\r\n",
        "brands_UnivAth['twitter_handle']=brands_UnivAth['twitter_handle'].astype(str)\r\n",
        "brands_UnivAth['twitter_handle']=brands_UnivAth['twitter_handle'].str.lower()\r\n",
        "brand_UnivAth_Handles_list = brands_UnivAth[\"twitter_handle\"].values.tolist()\r\n",
        "brand_UnivAth_Handles_list_pattern = '|'.join(brand_UnivAth_Handles_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756764
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset brand dataframe to take a single columns (twitter handle)\r\n",
        "#Create pattern for non-athletics university handles (i.e. @cuboulder)\r\n",
        "brands_UnivOther['twitter_handle']=brands_UnivOther['twitter_handle'].astype(str)\r\n",
        "brands_UnivOther['twitter_handle']=brands_UnivOther['twitter_handle'].str.lower()\r\n",
        "brand_UnivOther_Handles_list = brands_UnivOther[\"twitter_handle\"].values.tolist()\r\n",
        "brand_UnivOther_Handles_list_pattern = '|'.join(brand_UnivOther_Handles_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756785
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset brand dataframe to take a single columns (twitter handle)\r\n",
        "#Create pattern for pro sports handles (i.e. @broncos)\r\n",
        "brands_ProSports['twitter_handle']=brands_ProSports['twitter_handle'].astype(str)\r\n",
        "brands_ProSports['twitter_handle'].str.lower()\r\n",
        "brand_ProSports_Handles_list = brands_ProSports[\"twitter_handle\"].values.tolist()\r\n",
        "brand_ProSports_Handles_list_pattern = '|'.join(brand_ProSports_Handles_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756803
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset brand dataframe to take a single columns (brand names)\r\n",
        "#Create pattern for brand Names (i.e. ' best buy ')\r\n",
        "brands_NonUniv['brand_name']=brands_NonUniv['brand_name'].astype(str)\r\n",
        "brands_NonUniv['brand_name']=brands_NonUniv['brand_name'].str.lower()\r\n",
        "\r\n",
        "brands_NonUniv['brand_name']=brands_NonUniv['brand_name'].str.replace('(', '')\r\n",
        "brands_NonUniv['brand_name']=brands_NonUniv['brand_name'].str.replace(')', '')\r\n",
        "\r\n",
        "#remove TV network brands (this is it's own field)\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'abc']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'espn']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'espnu']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'espn2']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'espn3']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'fox']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'fs1']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'fs2']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'cbs']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'nbc']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'amazon prime']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'sec network']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'longhorn network']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'big ten network']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'byu tv']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'btn']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'acc network']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'pac 12 network']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'tbs']\r\n",
        "brands_NonUniv = brands_NonUniv.loc[brands_NonUniv['brand_name'] != 'mountainwest network']\r\n",
        "\r\n",
        "#Add space before and after brand name\r\n",
        "brands_NonUniv['brand_name2'] = ' ' + brands_NonUniv['brand_name'] + ' '\r\n",
        "\r\n",
        "brand_NonUniv_Names_list = brands_NonUniv['brand_name2'].values.tolist()\r\n",
        "brand_NonUniv_Names_list_pattern = '|'.join(brand_NonUniv_Names_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756824
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset brand dataframe to take a single columns (brand names)\r\n",
        "#Create pattern for college sports names (i.e. 'georgia bulldogs')\r\n",
        "brands_UnivAth['brand_name']=brands_UnivAth['brand_name'].astype(str)\r\n",
        "brands_UnivAth['brand_name']=brands_UnivAth['brand_name'].str.lower()\r\n",
        "\r\n",
        "brands_UnivAth['brand_name']=brands_UnivAth['brand_name'].str.replace('(', '')\r\n",
        "brands_UnivAth['brand_name']=brands_UnivAth['brand_name'].str.replace(')', '')\r\n",
        "\r\n",
        "brand_UnivAth_Names_list = brands_UnivAth['brand_name'].values.tolist()\r\n",
        "brand_UnivAth_Names_list_pattern = '|'.join(brand_UnivAth_Names_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756863
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset brand dataframe to take a single columns (brand names)\r\n",
        "#Create pattern for university non-ath names (i.e. 'purdue university')\r\n",
        "brands_UnivOther['brand_name']=brands_UnivOther['brand_name'].astype(str)\r\n",
        "brands_UnivOther['brand_name']=brands_UnivOther['brand_name'].str.lower()\r\n",
        "\r\n",
        "brands_UnivOther['brand_name']=brands_UnivOther['brand_name'].str.replace('(', '')\r\n",
        "brands_UnivOther['brand_name']=brands_UnivOther['brand_name'].str.replace(')', '')\r\n",
        "\r\n",
        "brand_UnivOther_Names_list = brands_UnivOther['brand_name'].values.tolist()\r\n",
        "brand_UnivOther_Names_list_pattern = '|'.join(brand_UnivOther_Names_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756884
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset brand dataframe to take a single columns (brand names)\r\n",
        "#Create pattern for pro sports names (i.e. 'atlanta hawks')\r\n",
        "brands_ProSports['brand_name']=brands_ProSports['brand_name'].astype(str)\r\n",
        "brands_ProSports['brand_name']=brands_ProSports['brand_name'].str.lower()\r\n",
        "\r\n",
        "brands_ProSports['brand_name']=brands_ProSports['brand_name'].str.replace('(', '')\r\n",
        "brands_ProSports['brand_name']=brands_ProSports['brand_name'].str.replace(')', '')\r\n",
        "brands_ProSports['brand_name']=brands_ProSports['brand_name'].str.replace('x - ', '')\r\n",
        "brands_ProSports['brand_name']=brands_ProSports['brand_name'].str.replace(' - x', '')\r\n",
        "\r\n",
        "brand_ProSports_Names_list = brands_ProSports['brand_name'].values.tolist()\r\n",
        "brand_ProSports_Names_list_pattern = '|'.join(brand_ProSports_Names_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create indicators columns to flag if handles/names of brands, college athletics\r\n",
        "#college non-athletics, and pro sports show up in Twitter content\r\n",
        "\r\n",
        "#Create flags to determine if tweet contains brand handles, names\r\n",
        "twitter2['Word_Brand_Handles_Flag'] = twitter2['PostMessage6'].str.contains(brand_NonUniv_Handles_list_pattern).astype(int)\r\n",
        "twitter2['Word_Brand_Names_Flag'] = twitter2['PostMessage6'].str.contains(brand_NonUniv_Names_list_pattern).astype(int)\r\n",
        "\r\n",
        "twitter2['Word_UnivAth_Handles_Flag'] = twitter2['PostMessage6'].str.contains(brand_UnivAth_Handles_list_pattern).astype(int)\r\n",
        "\r\n",
        "twitter2['Word_UnivOther_Handles_Flag'] = twitter2['PostMessage6'].str.contains(brand_UnivOther_Handles_list_pattern).astype(int)\r\n",
        "\r\n",
        "twitter2['Word_ProSports_Handles_Flag'] = twitter2['PostMessage6'].str.contains(brand_ProSports_Handles_list_pattern).astype(int)\r\n",
        "twitter2['Word_ProSports_Names_Flag'] = twitter2['PostMessage6'].str.contains(brand_ProSports_Names_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756934
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# At this point, proprietary data is pulled into the workspace\r\n",
        "# venue_dataset is a list of college athletics venues and\r\n",
        "# associated city names\r\n",
        "\r\n",
        "venue_dataset = Dataset.get_by_name(workspace, name='dimVenue')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756954
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to pandas dataframe\r\n",
        "venues = venue_dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756981
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pattern of college sports venue names (i.e. Kinnick Stadium) show up\r\n",
        "venues['venue_name']=venues['venue_name'].astype(str)\r\n",
        "venues['venue_name']=venues['venue_name'].str.lower()\r\n",
        "\r\n",
        "venues['venue_name']=venues['venue_name'].str.replace('(', '')\r\n",
        "venues['venue_name']=venues['venue_name'].str.replace(')', '')\r\n",
        "venues['venue_name']=venues['venue_name'].str.replace('x - ', '')\r\n",
        "venues['venue_name']=venues['venue_name'].str.replace(' - x', '')\r\n",
        "\r\n",
        "venue_name_list = venues['venue_name'].values.tolist()\r\n",
        "venue_name_list_pattern = '|'.join(venue_name_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775756999
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pattern of college sports city names (i.e. Iowa City) show up\r\n",
        "venues['city']=venues['city'].astype(str)\r\n",
        "venues['city']=venues['city'].str.lower()\r\n",
        "\r\n",
        "venues['city']=venues['city'].str.replace('(', '')\r\n",
        "venues['city']=venues['city'].str.replace(')', '')\r\n",
        "venues['city']=venues['city'].str.replace('x - ', '')\r\n",
        "venues['city']=venues['city'].str.replace(' - x', '')\r\n",
        "\r\n",
        "city_name_list = venues['city'].values.tolist()\r\n",
        "city_name_list_pattern = '|'.join(city_name_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757019
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Indicator columns to flag whether keywords from college sports venue and city list appear in tweet\r\n",
        "twitter2['Word_Venue_List_Flag'] = twitter2['PostMessage6'].str.contains(venue_name_list_pattern).astype(int)\r\n",
        "\r\n",
        "twitter2['Word_City_List_Flag'] = twitter2['PostMessage6'].str.contains(city_name_list_pattern).astype(int)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757046
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Indicator column: does Tweet contain \"team name\" (i.e. hawkeyes, sooners)\r\n",
        "#Import Team Names list for lookup\r\n",
        "\r\n",
        "teamnames = pd.read_csv('TeamName_Lookup_MITSloan.csv')\r\n",
        "teamnames[\"TeamNames\"]=teamnames[\"TeamNames\"].astype(str)\r\n",
        "teamnames[\"TeamNames\"]=teamnames[\"TeamNames\"].str.lower()\r\n",
        "\r\n",
        "#Convert to Team Names to list\r\n",
        "teamnames_list = teamnames[\"TeamNames\"].values.tolist()\r\n",
        "\r\n",
        "#Ad 'Or' operator to team names list -- use this pattern later in str.contains\r\n",
        "team_list_pattern = '|'.join(teamnames_list)\r\n",
        "\r\n",
        "#Create field -- inidcator columns for whether mascot shows up\r\n",
        "twitter2['Word_TeamName_Flag'] = twitter2['PostMessage6'].str.contains(team_list_pattern).astype(int)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757065
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create indicator columns for whether certain keywords (that don't require Fanbase integration)\r\n",
        "# appear in tweets\r\n",
        "\r\n",
        "#Birthday Flag\r\n",
        "birthday_list = ['birthday', 'hbd']\r\n",
        "birthday_list_pattern = '|'.join(birthday_list)\r\n",
        "twitter2['Word_Birthday_Flag'] = twitter2['PostMessage6'].str.contains(birthday_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Conference Flag \r\n",
        "conference_list = ['b1g', 'big ten', \r\n",
        "                'pac12', 'pac 12', 'pac-12', 'pac twelve'\r\n",
        "                'big 12', 'big twelve', 'big12',\r\n",
        "                ' sec ', \r\n",
        "                ' acc ',  \r\n",
        "                ' aac ','american athletic conference',\r\n",
        "                'mountain west', 'mwc',\r\n",
        "                'sunbelt',\r\n",
        "                'c-usa','conference usa',\r\n",
        "                'mid american conference',\r\n",
        "                ' mac ']  \r\n",
        "conference_list_pattern = '|'.join(conference_list)\r\n",
        "twitter2['Word_Conference_Flag'] = twitter2['PostMessage6'].str.contains(conference_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#TV Networks\r\n",
        "tvnetworks_list = ['abc','nbc',' fox ','fs1','fs1','espn', 'cbs',\r\n",
        "                'amazon prime', 'byu tv',\r\n",
        "                'espnu','espn2','big ten network','btn',\r\n",
        "                'sec network','acc network','pac 12 network',\r\n",
        "                'tbs','longhorn network','mountainwest network']\r\n",
        "                \r\n",
        "tvnetworks_list_pattern = '|'.join(tvnetworks_list)\r\n",
        "twitter2['Word_TVNetworks_Flag'] = twitter2['PostMessage6'].str.contains(tvnetworks_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#AM_PM Flag \r\n",
        "ampm_list = ['a.m.','p.m.','12 pm', '12pm', 'noon',\r\n",
        "                '1 pm','2 pm','3 pm','4 pm','5 pm','6 pm',\r\n",
        "                '7 pm','8 pm','9 pm', '10 pm', '11 pm',\r\n",
        "                '1 am','2 am','3 am','4 am','5 am','6 am',\r\n",
        "                '7 am','8 am','9 am', '10 am', '11 am',\r\n",
        "                 '1pm','2pm','3pm','4pm','5pm','6pm',\r\n",
        "                '7pm','8pm','9pm', '10pm', '11pm',\r\n",
        "                '1am','2am','3am','4am','5am','6am',\r\n",
        "                '7am','8am','9am', '10am', '11am',\r\n",
        "                ]            \r\n",
        "ampm_list_pattern = '|'.join(ampm_list)\r\n",
        "twitter2['Word_ampm_Flag'] = twitter2['PostMessage6'].str.contains(ampm_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Ticket \r\n",
        "ticket_list = ['ticket']\r\n",
        "                \r\n",
        "ticket_list_pattern = '|'.join(ticket_list)\r\n",
        "twitter2['Word_Ticket_Flag'] = twitter2['PostMessage6'].str.contains(ticket_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Congratulations\r\n",
        "congrats_list = ['congrat']\r\n",
        "                \r\n",
        "congrats_list_pattern = '|'.join(congrats_list)\r\n",
        "twitter2['Word_Congrats_Flag'] = twitter2['PostMessage6'].str.contains(congrats_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Holidays \r\n",
        "holiday_list = ['holiday', 'labor day',\r\n",
        "                'halloween', 'veterans day','veteran''s day',\r\n",
        "                'thanksgiving','christmas', 'new year',\r\n",
        "                'martin luther king jr day', \r\n",
        "                'martin luther king jr. day',\r\n",
        "                'mlk day', 'groundhog day',\r\n",
        "                'president''s day','presidents day',\r\n",
        "                'mardi gras',\r\n",
        "                'valentine','st. patrick','saint patrick',\r\n",
        "                 'easter', 'indigenous peoples day',\r\n",
        "                 'mother''s day','mothers day',\r\n",
        "                 'father''s day','fathers day',\r\n",
        "                'memorial day','cinco de mayo'\r\n",
        "                'juneteenth','flag day',\r\n",
        "                'fouth of july','4th of july','july 4th',\r\n",
        "                'happy fourth','happy 4th',\r\n",
        "                'july 4','independence day','black friday',\r\n",
        "                'patriots day','patriot''s day',\r\n",
        "                'kwanzaa','hanukkah','ramadan'\r\n",
        "                ]\r\n",
        "                \r\n",
        "holiday_list_pattern = '|'.join(holiday_list)\r\n",
        "twitter2['Word_Holiday_Flag'] = twitter2['PostMessage6'].str.contains(holiday_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Miliatry\r\n",
        "military_list = ['military','troops','veteran']               \r\n",
        "military_list_pattern = '|'.join(military_list)\r\n",
        "twitter2['Word_Military_Flag'] = twitter2['PostMessage6'].str.contains(military_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Day of Week\r\n",
        "dayofweek_list = ['monday','tuesday','wednesday','thursday','friday','saturday',\r\n",
        "                    'sunday']               \r\n",
        "dayofweek_list_pattern = '|'.join(dayofweek_list)\r\n",
        "twitter2['Word_DayofWeek_Flag'] = twitter2['PostMessage6'].str.contains(dayofweek_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Month\r\n",
        "month_list = ['january','february','march','april',' may ','june','july',\r\n",
        "                    'august','september','october','november','december']              \r\n",
        "month_list_pattern = '|'.join(month_list)\r\n",
        "twitter2['Word_Month_Flag'] = twitter2['PostMessage6'].str.contains(month_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Year - 1900s\r\n",
        "year1900s_list = ['1900','1901','1902','1903','1904','1905','1906',\r\n",
        "                    '1907','1908','1909','1910','1911','1912','1913','1914','1915','1916',\r\n",
        "                    '1917','1918','1919','20s','1920','1921','1922','1923','1924','1925','1926',\r\n",
        "                    '1927','1928','1929','30s','1930','1931','1932','1933','1934','1935','1936',\r\n",
        "                    '1937','1938','1939','40s','1940','1941','1942','1943','1944','1945','1946',\r\n",
        "                    '1947','1948','1949','50s','1950','1951','1952','1953','1954','1955','1956',\r\n",
        "                    '1957','1958','1959','60s','1960','1961','1962','1963','1964','1965','1966',\r\n",
        "                    '1967','1968','1969','70s','1970','1971','1972','1973','1974','1975','1976',\r\n",
        "                    '1977','1978','1979','80s','1980','1981','1982','1983','1984','1985','1986',\r\n",
        "                    '1987','1988','1989','90s','1990','1991','1992','1993','1994','1995','1996',\r\n",
        "                    '1997','1998','1999']\r\n",
        "year1900s_list_pattern = '|'.join(year1900s_list)\r\n",
        "twitter2['Word_Year1900s_Flag'] = twitter2['PostMessage6'].str.contains(year1900s_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#2000s\r\n",
        "Year2000s_list = ['2000','2001','2002','2003','2004','2005','2006',\r\n",
        "                    '2007','2008','2009']               \r\n",
        "Year2000s_list_pattern = '|'.join(Year2000s_list)\r\n",
        "twitter2['Word_Year2000s_Flag'] = twitter2['PostMessage6'].str.contains(Year2000s_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#2010s\r\n",
        "Year2010s_list = ['2010','2011','2012','2013','2014','2015','2016',\r\n",
        "                    '2017','2018','2019']               \r\n",
        "Year2010s_list_pattern = '|'.join(Year2010s_list)\r\n",
        "twitter2['Word_Year2010s_Flag'] = twitter2['PostMessage6'].str.contains(Year2010s_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#2020-22\r\n",
        "Year2020_22_list = ['2020','2021','2022']\r\n",
        "Year2020_22_list_pattern = '|'.join(Year2020_22_list)\r\n",
        "twitter2['Word_Year2020_22_Flag'] = twitter2['PostMessage6'].str.contains(Year2020_22_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#2023-29\r\n",
        "Year2023_29_list = ['2023','2024','2025', '2026','2027','2028','2029']\r\n",
        "Year2023_29_list_pattern = '|'.join(Year2023_29_list)\r\n",
        "twitter2['Word_Year2023_29_Flag'] = twitter2['PostMessage6'].str.contains(Year2023_29_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#coach\r\n",
        "coach_list = ['coach']\r\n",
        "coach_list_pattern = '|'.join(coach_list)\r\n",
        "twitter2['Word_Coach_Flag'] = twitter2['PostMessage6'].str.contains(coach_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Win\r\n",
        "win_list = [' win ','victory','winning',' won ', 'champions']\r\n",
        "win_list_pattern = '|'.join(win_list)\r\n",
        "twitter2['Word_Win_Flag'] = twitter2['PostMessage6'].str.contains(win_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Rank \r\n",
        "rank_list = ['ranking','ranked',' rank ']\r\n",
        "rank_list_pattern = '|'.join(rank_list)\r\n",
        "twitter2['Word_Rank_Flag'] = twitter2['PostMessage6'].str.contains(rank_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Pro Sports Leagues\r\n",
        "proleague_list = ['nfl','nba','nhl','mlb','wnba','pga','cfl']\r\n",
        "proleague_list_pattern = '|'.join(proleague_list)\r\n",
        "twitter2['Word_ProLeague_Flag'] = twitter2['PostMessage6'].str.contains(proleague_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Award\r\n",
        "award_list = ['award','of the year','of the year']\r\n",
        "award_list_pattern = '|'.join(award_list)\r\n",
        "twitter2['Word_Award_Flag'] = twitter2['PostMessage6'].str.contains(award_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Academics\r\n",
        "academics_list = ['academic','classroom','gpa']\r\n",
        "academics_list_pattern = '|'.join(academics_list)\r\n",
        "twitter2['Word_Academics_Flag'] = twitter2['PostMessage6'].str.contains(academics_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Donation\r\n",
        "donation_list = ['donation']\r\n",
        "donation_list_pattern = '|'.join(donation_list)\r\n",
        "twitter2['Word_Donation_Flag'] = twitter2['PostMessage6'].str.contains(donation_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#GameStats\r\n",
        "gamestats_list = ['touchdown','interception','completion',\r\n",
        "                    'field goal','extra point','safety',\r\n",
        "                    'penalty','yard','rush','sack','tackle',\r\n",
        "                    'time out','fumble','reception','pass',\r\n",
        "                    'hurries','touchback','punt','snap',\r\n",
        "                    'td','fg', '1st down', 'first down',\r\n",
        "                    '2nd down','second down','3rd down',\r\n",
        "                    'third down','4th down','fourth down',\r\n",
        "                    'turnover',\r\n",
        "                    'first half','1st half',\r\n",
        "                    'second half','2nd half',\r\n",
        "\r\n",
        "                    '1Q','Q1','2Q','Q2','3Q','Q3','4Q','Q4',\r\n",
        "\r\n",
        "                    'rebound','assist','free throw',\r\n",
        "                    '3 pointer','3 pt', \r\n",
        "                    'three pointer','three-pointer','3-pointer',\r\n",
        "                    '3 points', \r\n",
        "                    'foul', 'block', 'steal','double double',\r\n",
        "                    'triple double',\r\n",
        "\r\n",
        "                    'point',\r\n",
        "\r\n",
        "                    'inning','hits','rbi','stikeout','runs','error','home run'\r\n",
        "\r\n",
        "                    'kills', 'ace', 'attempt']\r\n",
        "\r\n",
        "gamestats_list_pattern = '|'.join(gamestats_list)\r\n",
        "twitter2['Word_GameStats_Flag'] = twitter2['PostMessage6'].str.contains(gamestats_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Time (Generic)\r\n",
        "time_generic_list = ['today','tomorrow','yesterday','weekend','week','tonight',\r\n",
        "                    'afternoon','morning','night','evening']\r\n",
        "time_generic_list_pattern = '|'.join(time_generic_list)\r\n",
        "twitter2['Word_Time_Generic_Flag'] = twitter2['PostMessage6'].str.contains(time_generic_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Position\r\n",
        "position_list = ['quarterback','quarter back','QB1','QB',\r\n",
        "                 'running back','runningback',\r\n",
        "                    'tight end',\r\n",
        "                    'receiver',\r\n",
        "                    'half back', 'halfback',\r\n",
        "                    'full back', 'fullback',\r\n",
        "                    'right tackle','right guard','center','left guard','left tackle',\r\n",
        "                    'offensive line','o line',\r\n",
        "                    'defensive line','d line',\r\n",
        "                    'd tackle','defensive tackle',\r\n",
        "                    'defensive end','d end', 'nose guard','nose tackle',\r\n",
        "                    'linebacker',\r\n",
        "                    'nickleback',\r\n",
        "                    'corner','cb','d back','defensive back',\r\n",
        "                    'safety', \r\n",
        "                    'kicker','punter','snapper','returner',\r\n",
        "\r\n",
        "                    'point guard','shooting guard','power forward','small forward',\r\n",
        "\r\n",
        "                    'pitcher','catcher','first base','1st base','second base',\r\n",
        "                    '2nd base','third base','3rd base','outfield','short stop',\r\n",
        "\r\n",
        "                    'hitter', 'setter', 'middle blocker', 'libero', \r\n",
        "                    'specialist']\r\n",
        "\r\n",
        "position_list_pattern = '|'.join(position_list)\r\n",
        "twitter2['Word_Position_Flag'] = twitter2['PostMessage6'].str.contains(position_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#GenZ Terms\r\n",
        "genz_terms_list = ['vibe','vibing',\r\n",
        "                    'hits different','hits dif'\r\n",
        "                    ' drip ',\r\n",
        "                    ' no cap ',\r\n",
        "                    'main character',\r\n",
        "                    'understood the assignment','understand the assignment', 'understands the assignment'\r\n",
        "                    ' slaps '\r\n",
        "                    'low key','low-key', 'lowkey',\r\n",
        "                    'high key','high-key', 'highkey',\r\n",
        "                    'bussin',\r\n",
        "                    'glow up',\r\n",
        "                    'big yikes', \r\n",
        "                    'finna',\r\n",
        "                    'sip tea',\r\n",
        "                    'yeet',\r\n",
        "                    'savage',\r\n",
        "                     'iykyk',\r\n",
        "                     ' flex ',\r\n",
        "                     ' lit ',\r\n",
        "                     'finesse',\r\n",
        "                     'savage']\r\n",
        "genz_terms_list_pattern = '|'.join(genz_terms_list)\r\n",
        "twitter2['Word_GenZ_Terms_Flag'] = twitter2['PostMessage6'].str.contains(genz_terms_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Venue \r\n",
        "venue_list = ['stadium','arena','dome','court']\r\n",
        "venue_list_pattern = '|'.join(venue_list)\r\n",
        "twitter2['Word_Venue_Flag'] = twitter2['PostMessage6'].str.contains(venue_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Schedule \r\n",
        "schedule_list = ['schedule']\r\n",
        "schedule_list_pattern = '|'.join(schedule_list)\r\n",
        "twitter2['Word_Schedule_Flag'] = twitter2['PostMessage6'].str.contains(schedule_list_pattern).astype(int)\r\n",
        "\r\n",
        "\r\n",
        "#Colors\r\n",
        "color_list = [' red ', \r\n",
        "            'blue','yellow','gold','black',\r\n",
        "                'white','green','purple','crimson','scarlet',\r\n",
        "                        'orange','maroon','silver','cream',\r\n",
        "                        'brown','cardinal','grey']\r\n",
        "color_list_pattern = '|'.join(color_list)\r\n",
        "twitter2['Word_Color_Flag'] = twitter2['PostMessage6'].str.contains(color_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Free\r\n",
        "free_list = ['free','giveaway']\r\n",
        "free_list_pattern = '|'.join(free_list)\r\n",
        "twitter2['Word_Free_Flag'] = twitter2['PostMessage6'].str.contains(free_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Presented By\r\n",
        "presentedby_list = ['presented by']\r\n",
        "presentedby_list_pattern = '|'.join(presentedby_list)\r\n",
        "twitter2['Word_PresentedBy_Flag'] = twitter2['PostMessage6'].str.contains(presentedby_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Ready To\r\n",
        "ready_list = ['ready']\r\n",
        "ready_list_pattern = '|'.join(ready_list)\r\n",
        "twitter2['Word_Ready_Flag'] = twitter2['PostMessage6'].str.contains(ready_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Throwback\r\n",
        "throwback_list = ['throwback','flashback','tbt']\r\n",
        "throwback_list_pattern = '|'.join(throwback_list)\r\n",
        "twitter2['Word_Throwback_Flag'] = twitter2['PostMessage6'].str.contains(throwback_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Thanks\r\n",
        "thank_list = ['thank']\r\n",
        "thank_list_pattern = '|'.join(thank_list)\r\n",
        "twitter2['Word_Thanks_Flag'] = twitter2['PostMessage6'].str.contains(thank_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Good luck\r\n",
        "goodluck_list = ['good luck']\r\n",
        "goodluck_list_pattern = '|'.join(goodluck_list)\r\n",
        "twitter2['Word_GoodLuck_Flag'] = twitter2['PostMessage6'].str.contains(goodluck_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Celebrate\r\n",
        "celebrate_list = ['celebrate']\r\n",
        "celebrate_list_pattern = '|'.join(celebrate_list)\r\n",
        "twitter2['Word_Celebrate_Flag'] = twitter2['PostMessage6'].str.contains(celebrate_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Be sure\r\n",
        "be_sure_list = ['be sure']\r\n",
        "be_sure_list_pattern = '|'.join(be_sure_list)\r\n",
        "twitter2['Word_Be_Sure_Flag'] = twitter2['PostMessage6'].str.contains(be_sure_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Against vs. \r\n",
        "against_list = ['against','vs']\r\n",
        "against_list_pattern = '|'.join(against_list)\r\n",
        "twitter2['Word_Against_Flag'] = twitter2['PostMessage6'].str.contains(against_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Game\r\n",
        "game_list = ['game']\r\n",
        "game_list_pattern = '|'.join(game_list)\r\n",
        "twitter2['Word_Game_Flag'] = twitter2['PostMessage6'].str.contains(game_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Team\r\n",
        "team_list = ['team']\r\n",
        "team_list_pattern = '|'.join(team_list)\r\n",
        "twitter2['Word_Team_Flag'] = twitter2['PostMessage6'].str.contains(team_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Back to\r\n",
        "back_list = ['back to','back at']\r\n",
        "back_list_pattern = '|'.join(back_list)\r\n",
        "twitter2['Word_Back_To_Flag'] = twitter2['PostMessage6'].str.contains(back_list_pattern).astype(int)\r\n",
        "\r\n",
        "#Sport\r\n",
        "sport_list = ['football','basketball','mbb','wbb','baseball','softball',\r\n",
        "            'hockey','soccer','tennis','golf','rowing','volleyball',\r\n",
        "            'cross country','swim','dive','track','wrestling','gymnastic',\r\n",
        "            'lacrosse','water polo']\r\n",
        "sport_list_pattern = '|'.join(sport_list)\r\n",
        "twitter2['Word_Sport_Flag'] = twitter2['PostMessage6'].str.contains(sport_list_pattern).astype(int)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757091
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop any tweets with 0 impressions to avoid NaN share rates\r\n",
        "twitter3 = twitter2.drop(twitter2[twitter2.Impressions <1].index)\r\n",
        "twitter3 = twitter3.drop(twitter3[twitter3.Impressions.isnull()].index)\r\n",
        "twitter3 = twitter3.drop(twitter3[twitter3.Impressions.isna()].index)\r\n",
        "twitter3 = twitter3.drop(twitter3[twitter3.Impressions==''].index)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757175
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simplify Dataset (reduce columns)\r\n",
        "\r\n",
        "Twitter_Simple = twitter3[['Handle',\r\n",
        "\r\n",
        "'VideoFlag',\r\n",
        "\r\n",
        "'Fri_to_Sunday_Flag',\r\n",
        "\r\n",
        "'Sport_Football',\r\n",
        "'Sport_Main Athletics',\r\n",
        "'Sport_Men\\'s Basketball',\r\n",
        "'Sport_Women\\'s Basketball',\r\n",
        "'Sport_Olympic',\r\n",
        "\r\n",
        "'P5_Conference_Flag',\r\n",
        "\r\n",
        "'Month_Sep_Oct',\r\n",
        "'Month_Nov_Dec',\r\n",
        "'Month_Jan_Feb',\r\n",
        "'Month_Mar_Apr',\r\n",
        "'Month_May_June',\r\n",
        "'Month_July_Aug',\r\n",
        "\r\n",
        "'Exlaim_Mark_Count',\r\n",
        "'Question_Mark_Count',\r\n",
        "'Hashtag_Count',\r\n",
        "'Mention_Count',\r\n",
        "'Line_Break_Count',\r\n",
        "'Link_Count_v2',\r\n",
        "'Word_Count',\r\n",
        "'Emoji_Count',\r\n",
        "\r\n",
        "'SentScore_Compound',\r\n",
        "\r\n",
        "'Total_Verb_Perc_of_Words',\r\n",
        "'Total_Adjective_Perc_of_Words',\r\n",
        "'Total_Adverb_Perc_of_Words',\r\n",
        "'Total_Noun_Perc_of_Words',\r\n",
        "'Total_Digit_Perc_of_Words',\r\n",
        "\r\n",
        "'Word_GenZ_Terms_Flag',\r\n",
        "'Word_TeamName_Flag',\r\n",
        "'Word_Time_Generic_Flag',\r\n",
        "'Word_GameStats_Flag',\r\n",
        "'Word_City_List_Flag',\r\n",
        "'Word_Sport_Flag',\r\n",
        "'Word_ampm_Flag',\r\n",
        "'Word_Game_Flag',\r\n",
        "'Word_UnivAth_Handles_Flag',\r\n",
        "'Word_Win_Flag',\r\n",
        "'Word_Coach_Flag',\r\n",
        "'Word_Brand_Handles_Flag',\r\n",
        "'Word_Position_Flag',\r\n",
        "'Word_UnivOther_Handles_Flag',\r\n",
        "'Word_Ticket_Flag',\r\n",
        "'Word_ProLeague_Flag',\r\n",
        "'Word_ProSports_Names_Flag',\r\n",
        "'Word_Thanks_Flag',\r\n",
        "'Word_Free_Flag',\r\n",
        "'Word_Award_Flag',\r\n",
        "'Word_Rank_Flag',\r\n",
        "'Word_Birthday_Flag',\r\n",
        "'Word_TVNetworks_Flag',\r\n",
        "'Word_PresentedBy_Flag',\r\n",
        "'Word_Year1900s_Flag',\r\n",
        "'Word_Year2000s_Flag',\r\n",
        "'Word_Year2010s_Flag',\r\n",
        "\r\n",
        "'Emo_Sports_Objects_Flag',\r\n",
        "'Emo_heavyexclaimation_Flag',\r\n",
        "'Emo_animal_Flag',\r\n",
        "'Emo_TV_Radio_Flag',\r\n",
        "'Emo_arrows_Flag',\r\n",
        "'Emo_numbers_Flag',\r\n",
        "'Emo_circle_Flag',\r\n",
        "'Emo_Bar_chart_Flag',\r\n",
        "'Emo_eyes_Flag',\r\n",
        "'Emo_newspaper_Flag',\r\n",
        "'Emo_muscle_Flag',\r\n",
        "'Emo_Round_Pushpin_Flag',\r\n",
        "'Emo_rotating_light_Flag',\r\n",
        "'Emo_link_Flag',\r\n",
        "'Emo_fire_Flag',\r\n",
        "'Emo_heart_Flag',\r\n",
        "'Emo_triumph_Flag',\r\n",
        "'Emo_handgesture_Flag',\r\n",
        "'Emo_vs_Flag',\r\n",
        "'Emo_trophyring_Flag',\r\n",
        "\r\n",
        "\r\n",
        "'Impressions',\r\n",
        "'VideoViews',\r\n",
        "'Likes',\r\n",
        "'Comments',\r\n",
        "'Shares',\r\n",
        "'Share_Rate',\r\n",
        "'Comment_Rate',\r\n",
        "'Like_Rate',\r\n",
        "'Total_SCLs',\r\n",
        "'SCL_Rate'\r\n",
        "\r\n",
        "]]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757201
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Twitter_Simple.rename({'Sport_Men\\'s Basketball': 'Sport_MBB', \r\n",
        "                            'Sport_Women\\'s Basketball': 'Sport_WBB',\r\n",
        "                            'Sport_Main Athletics':'Sport_Main_Athletics'}, axis=1, inplace=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757225
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import datframe containing Wiland demographics (data is proprietary, so file is not provided)\r\n",
        "#Contains brekdown of age of followers for given handles\r\n",
        "\r\n",
        "all_wiland = pd.read_csv('wiland_demos_MIT_Sloan_82922.csv')\r\n",
        "all_wiland.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757245
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Consolidate Wiland Dataset\r\n",
        "#Create Wiland field for 18 to 25\r\n",
        "\r\n",
        "all_wiland['Wiland_Age_18_25']= all_wiland['wiland_age_18_20']+all_wiland['wiland_age_21_25']\r\n",
        "all_wiland['Wiland_Age_26_35']= all_wiland['wiland_age_26_30']+all_wiland['wiland_age_31_35']\r\n",
        "all_wiland['Wiland_Age_36_50']= all_wiland['wiland_age_36_40']+all_wiland['wiland_age_41_45']+all_wiland['wiland_age_46_50']\r\n",
        "all_wiland['Wiland_Age_Over50']= all_wiland['wiland_age_51_55']+all_wiland['wiland_age_56_60']+all_wiland['wiland_age_61_65']+all_wiland['wiland_age_66_70']+all_wiland['wiland_age_71_75']+all_wiland['wiland_age_76+']\r\n",
        "\r\n",
        "all_wiland['Wiland_Income_Over100k']=all_wiland['wiland_income_100K_124K']+all_wiland['wiland_income_125Kplus']\r\n",
        "\r\n",
        "all_wiland['wiland_urbanicity_rural_consol']=all_wiland['wiland_urbanicity_Highly_Rural_Community']+all_wiland['wiland_urbanicity_Rural_Community']\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757264
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simplify wiland columns\r\n",
        "\r\n",
        "all_wiland2 = all_wiland[['Handle_Key',\r\n",
        "'Wiland_Age_18_25',\r\n",
        "'Wiland_Age_26_35',\r\n",
        "'Wiland_Age_36_50',\r\n",
        "'Wiland_Age_Over50',\r\n",
        "\r\n",
        "'Wiland_Income_Over100k',\r\n",
        "\r\n",
        "'wiland_urbanicity_rural_consol',\r\n",
        "'wiland_urbanicity_Urban_Community',\r\n",
        "'wiland_urbanicity_Suburban_Community',\r\n",
        "\r\n",
        "'wiland_eth_Asian',\r\n",
        "'wiland_eth_African_American',\r\n",
        "'wiland_eth_Hispanic',\r\n",
        "'wiland_eth_White',\r\n",
        "\r\n",
        "'wiland_hh_comp_Married',\r\n",
        "'wiland_hh_comp_Children_Present'\r\n",
        "\r\n",
        "]]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757285
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Join Wiland data with larger dataframe of Twitter data\r\n",
        "\r\n",
        "Tw_Gran_Wiland = pd.merge(Twitter_Simple,all_wiland2,\r\n",
        "            left_on='Handle',\r\n",
        "            right_on='Handle_Key',\r\n",
        "            how='left',\r\n",
        "            left_index=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757316
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop Rows with NA values for Wiland Age demos\r\n",
        "\r\n",
        "Tw_Gran_Wiland_FILT = Tw_Gran_Wiland.drop(Tw_Gran_Wiland[Tw_Gran_Wiland.Wiland_Age_18_25.isnull()].index)\r\n",
        "\r\n",
        "Tw_Gran_Wiland_FILT = Tw_Gran_Wiland_FILT.drop(Tw_Gran_Wiland_FILT[Tw_Gran_Wiland_FILT.Wiland_Age_18_25.isna()].index)\r\n",
        "\r\n",
        "Tw_Gran_Wiland_FILT = Tw_Gran_Wiland_FILT.drop(Tw_Gran_Wiland_FILT[Tw_Gran_Wiland_FILT.Wiland_Age_18_25==''].index)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757343
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting Engagement at tweet level -- include Wiland fields\r\n",
        "#Features were selected based on frequencies, relevance\r\n",
        "\r\n",
        "Tw_Gran_Wiland_Model = Tw_Gran_Wiland_FILT[[\r\n",
        "'Handle', #Used to identify subset of handles w/ highest and lowest % of GenZ followers (18-25) -- drop for modeling\r\n",
        "\r\n",
        "'VideoFlag',\r\n",
        "'Fri_to_Sunday_Flag',\r\n",
        "'P5_Conference_Flag',\r\n",
        "'Month_Sep_Oct',\r\n",
        "'Month_Nov_Dec',\r\n",
        "'Month_Jan_Feb',\r\n",
        "'Month_Mar_Apr',\r\n",
        "'Month_July_Aug',\r\n",
        "'Exclaim_Mark_Count',\r\n",
        "'Question_Mark_Count',\r\n",
        "'Hashtag_Count',\r\n",
        "'Mention_Count',\r\n",
        "'Line_Break_Count',\r\n",
        "'Link_Count_v2',\r\n",
        "'Word_Count',\r\n",
        "'Emoji_Count',\r\n",
        "'SentScore_Compound',\r\n",
        "'Total_Verb_Perc_of_Words',\r\n",
        "'Total_Adjective_Perc_of_Words',\r\n",
        "'Total_Adverb_Perc_of_Words',\r\n",
        "'Total_Noun_Perc_of_Words',\r\n",
        "'Total_Digit_Perc_of_Words',\r\n",
        "'Word_GenZ_Terms_Flag',\r\n",
        "'Word_TeamName_Flag',\r\n",
        "'Word_Time_Generic_Flag',\r\n",
        "'Word_GameStats_Flag',\r\n",
        "'Word_City_List_Flag',\r\n",
        "'Word_Sport_Flag',\r\n",
        "'Word_ampm_Flag',\r\n",
        "'Word_Game_Flag',\r\n",
        "'Word_UnivAth_Handles_Flag',\r\n",
        "'Word_Win_Flag',\r\n",
        "'Word_Coach_Flag',\r\n",
        "'Word_Brand_Handles_Flag',\r\n",
        "'Word_Position_Flag',\r\n",
        "'Word_UnivOther_Handles_Flag',\r\n",
        "'Word_Ticket_Flag',\r\n",
        "'Word_ProLeague_Flag',\r\n",
        "'Word_ProSports_Names_Flag',\r\n",
        "'Word_Thanks_Flag',\r\n",
        "'Word_Free_Flag',\r\n",
        "'Word_Award_Flag',\r\n",
        "'Word_Rank_Flag',\r\n",
        "'Word_Birthday_Flag',\r\n",
        "'Word_TVNetworks_Flag',\r\n",
        "'Word_PresentedBy_Flag',\r\n",
        "'Word_Year1900s_Flag',\r\n",
        "'Word_Year2000s_Flag',\r\n",
        "'Word_Year2010s_Flag',\r\n",
        "'Emo_Sports_Objects_Flag',\r\n",
        "'Emo_heavyexclaimation_Flag',\r\n",
        "'Emo_animal_Flag',\r\n",
        "'Emo_TV_Radio_Flag',\r\n",
        "'Emo_arrows_Flag',\r\n",
        "'Emo_numbers_Flag',\r\n",
        "'Emo_circle_Flag',\r\n",
        "'Emo_Bar_chart_Flag',\r\n",
        "'Emo_eyes_Flag',\r\n",
        "'Emo_newspaper_Flag',\r\n",
        "'Emo_muscle_Flag',\r\n",
        "'Emo_Round_Pushpin_Flag',\r\n",
        "'Emo_rotating_light_Flag',\r\n",
        "'Emo_link_Flag',\r\n",
        "'Emo_fire_Flag',\r\n",
        "'Emo_heart_Flag',\r\n",
        "'Emo_triumph_Flag',\r\n",
        "'Emo_handgesture_Flag',\r\n",
        "'Emo_vs_Flag',\r\n",
        "'Emo_trophyring_Flag',\r\n",
        "\r\n",
        "'Wiland_Age_18_25', #Age 18-25 % to be used to identify accounts with highest and lowest % of Gen Z\r\n",
        "\r\n",
        "'Share_Rate', #Share Rate (Retweet Rate) to be used for Y (dependent) variable\r\n",
        "'Comment_Rate',\r\n",
        "'Like_Rate',\r\n",
        "'SCL_Rate'\r\n",
        "\r\n",
        "]]\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757425
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert NaN Part of Speech % fields to 0\r\n",
        "Tw_Gran_Wiland_Model['Total_Verb_Perc_of_Words'] = Tw_Gran_Wiland_Model['Total_Verb_Perc_of_Words'].fillna(0)\r\n",
        "Tw_Gran_Wiland_Model['Total_Adjective_Perc_of_Words'] = Tw_Gran_Wiland_Model['Total_Adjective_Perc_of_Words'].fillna(0)\r\n",
        "Tw_Gran_Wiland_Model['Total_Adverb_Perc_of_Words'] = Tw_Gran_Wiland_Model['Total_Adverb_Perc_of_Words'].fillna(0)\r\n",
        "Tw_Gran_Wiland_Model['Total_Noun_Perc_of_Words'] = Tw_Gran_Wiland_Model['Total_Noun_Perc_of_Words'].fillna(0)\r\n",
        "Tw_Gran_Wiland_Model['Total_Digit_Perc_of_Words'] = Tw_Gran_Wiland_Model['Total_Digit_Perc_of_Words'].fillna(0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757589
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#End Feature Engineering Code"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1663775757695
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}